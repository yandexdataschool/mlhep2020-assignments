{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Adversarial AutoEncoder (extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_free_gpu():\n",
    "    from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo, nvmlDeviceGetCount\n",
    "    nvmlInit()\n",
    "\n",
    "    return np.argmax([\n",
    "        nvmlDeviceGetMemoryInfo(nvmlDeviceGetHandleByIndex(i)).free\n",
    "        for i in range(nvmlDeviceGetCount())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cuda_id = get_free_gpu()\n",
    "    DEVICE = 'cuda:%d' % (get_free_gpu(), )\n",
    "    print('Selected %s' % (DEVICE, ))\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "    print('WARNING: using cpu!')\n",
    "\n",
    "### please, don't remove the following line\n",
    "x = torch.tensor([1], dtype=torch.float32).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(filename):\n",
    "    from IPython import display\n",
    "    try:\n",
    "        display.display(\n",
    "            display.Image(filename=filename)\n",
    "        )\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, n_classes=10):\n",
    "    y_ = np.zeros(shape=(y.shape[0], n_classes), dtype='float32')\n",
    "    y_[np.arange(y.shape[0]), y] = 1\n",
    "    \n",
    "    return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "ds_train = MNIST(\"../../data/\", train=True, download=True)\n",
    "ds_test = MNIST(\"../../data/\", train=False, download=True)\n",
    "\n",
    "data_train = \\\n",
    "    ds_train.data.reshape(-1, 1, 28, 28).detach().numpy().astype(np.float32) / 255\n",
    "\n",
    "labels_train = ds_train.targets.detach().numpy()\n",
    "\n",
    "### to make everything fast we transfer the entire dataset into GPU\n",
    "X_train = torch.tensor(data_train, dtype=torch.float32, device=DEVICE)\n",
    "y_train = torch.tensor(labels_train, dtype=torch.long, device=DEVICE)\n",
    "y_one_hot_train = torch.tensor(one_hot(labels_train), dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "X_avg = torch.mean(X_train, dim=0)\n",
    "MSE_baseline = torch.mean((X_train - X_avg[None, :, :, :]) ** 2)\n",
    "\n",
    "data_test = \\\n",
    "    ds_test.data.reshape(-1, 1, 28, 28).detach().numpy().astype(np.float32) / 255\n",
    "\n",
    "labels_test = ds_test.targets.detach().numpy()\n",
    "\n",
    "X_test = torch.tensor(data_test, dtype=torch.float32, device=DEVICE)\n",
    "y_test = torch.tensor(labels_test, dtype=torch.long, device=DEVICE)\n",
    "y_one_hot_test = torch.tensor(one_hot(labels_test), dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "dataset_test = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_test, y_test),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6), dpi=100)\n",
    "plt.axis('off')\n",
    "_ = plt.imshow(\n",
    "    np.concatenate(\n",
    "        np.concatenate(data_train[:200].reshape(20, 10, 28, 28), axis=2),\n",
    "        axis=0\n",
    "    ),\n",
    "    cmap=plt.cm.Greys\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(torch.nn.Module):\n",
    "    def __init__(self, *shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fully convolutional network\n",
    "### aka encoder\n",
    "### E: (None, 1, 28, 28), (None, additional_z_size) -> (None, code_size)\n",
    "class Inference(torch.nn.Module):\n",
    "    def __init__(self, n, code_size, xi_size=None):\n",
    "        super(Inference, self).__init__()\n",
    "        \n",
    "        self.image_embedding = [\n",
    "            ### 26 x 26\n",
    "            torch.nn.Conv2d(1, 2 * n, kernel_size=3, stride=1), torch.nn.LeakyReLU(),\n",
    "            ### 24 x 24\n",
    "            torch.nn.Conv2d(2 * n, 2 * n, kernel_size=3, stride=1), torch.nn.LeakyReLU(),\n",
    "            ### 12 x 12, conv pooling\n",
    "            torch.nn.Conv2d(2 * n, 2 * n, kernel_size=2, stride=2), torch.nn.LeakyReLU(),\n",
    "\n",
    "            ### 10 x 10\n",
    "            torch.nn.Conv2d(2 * n, 3 * n, kernel_size=3, stride=1), torch.nn.LeakyReLU(),\n",
    "            ### 8 x 8\n",
    "            torch.nn.Conv2d(3 * n, 3 * n, kernel_size=3, stride=1), torch.nn.LeakyReLU(),\n",
    "            ### 4 x 4, conv pooling\n",
    "            torch.nn.Conv2d(3 * n, 3 * n, kernel_size=2, stride=2), torch.nn.LeakyReLU(),\n",
    "            \n",
    "\n",
    "            ### 2 x 2\n",
    "            torch.nn.Conv2d(3 * n, 4 * n, kernel_size=3, stride=1), torch.nn.LeakyReLU(),\n",
    "            ### 1 x 1\n",
    "            torch.nn.Conv2d(4 * n, code_size, kernel_size=2, stride=1),\n",
    "\n",
    "            torch.nn.Flatten()\n",
    "        ]\n",
    "        \n",
    "        for i, f in enumerate(self.image_embedding):\n",
    "            self.add_module('img_embedding%d' % (i, ), f)\n",
    "        \n",
    "        xi_size = 0 if xi_size is None else xi_size\n",
    "        \n",
    "        self.combined = [\n",
    "            torch.nn.Linear(code_size + xi_size, 2 * code_size), torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(2 * code_size, code_size)\n",
    "        ]\n",
    "        \n",
    "        for i, f in enumerate(self.combined):\n",
    "            self.add_module('combined%d' % (i, ), f)\n",
    "\n",
    "    def forward(self, x, z=None):\n",
    "        for f in self.image_embedding:\n",
    "            x = f(x)\n",
    "        \n",
    "        if z is not None:\n",
    "            x = torch.cat([x, z], dim=1)\n",
    "        \n",
    "        for f in self.combined:\n",
    "            x = f(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### aka decoder\n",
    "### G: (None, code_size) -> (None, 1, 28, 28)\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, n, code_size):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.modules = [\n",
    "            torch.nn.Linear(code_size, 4 * n),\n",
    "            View(-1, 4 * n, 1, 1),\n",
    "            \n",
    "            ### 2 x 2\n",
    "            torch.nn.ConvTranspose2d(4 * n, 4 * n, kernel_size=2, stride=1),\n",
    "            ### 4 x 4\n",
    "            torch.nn.ConvTranspose2d(4 * n, 3 * n, kernel_size=3, stride=1),\n",
    "            torch.nn.LeakyReLU(),\n",
    "\n",
    "            ### 8 x 8\n",
    "            torch.nn.ConvTranspose2d(3 * n, 3 * n, kernel_size=2, stride=2),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            ### 10 x 10\n",
    "            torch.nn.ConvTranspose2d(3 * n, 3 * n, kernel_size=3, stride=1),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            ### 12 x 12\n",
    "            torch.nn.ConvTranspose2d(3 * n, 2 * n, kernel_size=3, stride=1),\n",
    "            torch.nn.LeakyReLU(),\n",
    "\n",
    "            ### 24 x 24\n",
    "            torch.nn.ConvTranspose2d(2 * n, 2 * n, kernel_size=2, stride=2),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            ### 26 x 26\n",
    "            torch.nn.ConvTranspose2d(2 * n, 2 * n, kernel_size=3, stride=1),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            ### 28 x 28\n",
    "            torch.nn.ConvTranspose2d(2 * n, 1, kernel_size=3, stride=1),\n",
    "        ]\n",
    "        \n",
    "        for i, f in enumerate(self.modules):\n",
    "            self.add_module('f%d' % (i, ), f)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        x = z\n",
    "\n",
    "        for f in self.modules:\n",
    "            x = f(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### aka critic\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, n, input_size, n_outputs=None):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.fs = [\n",
    "            torch.nn.Linear(input_size, 2 * n),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            \n",
    "            torch.nn.Linear(2 * n, n),\n",
    "            torch.nn.LeakyReLU(),\n",
    "        ]\n",
    "        \n",
    "        if n_outputs is None:\n",
    "            self.fs.append(torch.nn.Linear(n, 1))\n",
    "        else:\n",
    "            self.fs.append(torch.nn.Linear(n, n_outputs))\n",
    "                \n",
    "        \n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        for i, f in enumerate(self.fs):\n",
    "            self.add_module('f%d' % (i, ), f)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for f in self.fs:\n",
    "            x = f(x)\n",
    "        \n",
    "        if self.n_outputs is None:\n",
    "            return x.view(-1)\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate(f, n_epoches, n_steps, callback=None):\n",
    "    losses = np.zeros((n_epoches, n_batches), dtype=np.float32)\n",
    "\n",
    "    primary_pbar = tqdm(total=n_epoches, leave=False)\n",
    "    secondary_pbar = tqdm(total=n_steps, leave=False)\n",
    "\n",
    "    for i in range(n_epoches):\n",
    "        secondary_pbar.reset()\n",
    "\n",
    "        for j in range(n_steps):\n",
    "            losses[i, j] = f()\n",
    "\n",
    "            secondary_pbar.update()\n",
    "\n",
    "        primary_pbar.update()\n",
    "        if callback is not None:\n",
    "            callback()\n",
    "\n",
    "    secondary_pbar.close()\n",
    "    primary_pbar.close()\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Training procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "### discriminator is a light-weight network, thus,\n",
    "### can easily handle large batches\n",
    "batch_size_discr_real = 32\n",
    "batch_size_discr_prior = 128\n",
    "\n",
    "n_epoches = 4\n",
    "\n",
    "n_batches = len(data_train) // batch_size\n",
    "\n",
    "n = 16\n",
    "code_size = 16\n",
    "xi_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_binary_crossentropy(predictions_positive, predictions_negative):\n",
    "    \"\"\"\n",
    "    Accepts logits (output of a network before sigmoid or softmax) and returns cross-entropy loss.\n",
    "    - predictions_positive - predictions on real samples (y = 1);\n",
    "    - predictions_negative - predictions on generated samples (y = 0);\n",
    "    \"\"\"\n",
    "\n",
    "    ### -log sigmoid(p) = log( 1 + exp(-p) ) = softplus(-p)\n",
    "    return torch.mean(\n",
    "        torch.nn.functional.softplus(-predictions_positive)\n",
    "    ) + torch.mean(\n",
    "        torch.nn.functional.softplus(predictions_negative)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Feature disentanglement (extra, not graded)\n",
    "\n",
    "You are task with implementing a feature disentanglement!\n",
    "Here, features are labels, i.e., which digit is shown on the image.\n",
    "\n",
    "1. The idea is simple - add another discriminator, that tries to predict labels given latent representation fron the inference network:\n",
    "\n",
    "$$d' : \\mathcal{Z} \\to \\mathbb{R}^{10}$$\n",
    "\n",
    "2. Then, using this new discriminator penalize the latent variables for containing information about the labels.\n",
    "However, generator will have a hard time reconstructing the original input with any information about the label. Thus, we introduce it back --- ground-truth labels (one-hot encoded) are supplied directly to the generator!\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\\mathcal{L} &=& \\mathrm{MSE} + \\alpha \\cdot \\mathrm{penalty}_Z + \\beta \\cdot \\mathrm{penalty}_y ;\\\\\n",
    "\\mathrm{MSE} &=& \\mathbb{E}_{x, y, \\xi} \\big( \\mathrm{generator}(\\mathrm{inference}(x, \\xi), y) - x \\big)^2;\\\\\n",
    "\\mathrm{penalty}_Z &=& \\mathbb{E}_{x, \\xi} \\log d(\\mathrm{inference}(x, \\xi));\\\\\n",
    "\\mathrm{penalty}_y &=& \\mathbb{E}_{x, y, \\xi} y \\log d'(\\mathrm{inference}(x, \\xi))\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "where:\n",
    "- $y \\in \\mathbb{R}^{10}$ --- one-hot encoded vector of labels;\n",
    "- $d$ --- the discriminator trained to distinguish $\\mathrm{inference}(x, \\xi)$ from $\\mathcal{N}^m(0, 1)$;\n",
    "- $d'$ --- the label discriminator trained to predict labels $y$ given latent variables $\\mathrm{inference}(x, \\xi)$.\n",
    "\n",
    "*(note signs)*\n",
    "\n",
    "You can find more details in the [original paper](https://arxiv.org/abs/1511.05644), section 4. The only difference from the original AAE is that we explicitly penalize latent variabels for containing label information.\n",
    "\n",
    "Notice, however, that $\\beta$ can be set to a low value since $\\mathrm{penalty}_y$ has no conflict with the main objective, $\\mathrm{MSE}$, i.e. it is possible to achieve minimum of the both loss functions simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "289617dcdfeed4781b6f5ba3e8f6bf23",
     "grade": false,
     "grade_id": "AAE-discriminator",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_step_discriminator(inference, discriminator, opt_discriminator):\n",
    "    def step():\n",
    "        with torch.no_grad():\n",
    "            indx = torch.randint(low=0, high=X_train.shape[0], size=(batch_size_discr_real, ), device=DEVICE)\n",
    "            X_batch = X_train[indx]\n",
    "            \n",
    "            ### xi makes inference stochastic\n",
    "            xi = torch.randn(X_batch.shape[0], xi_size, device=DEVICE)\n",
    "            Z_inferred = inference(X_batch, xi)\n",
    "            \n",
    "            Z_prior = torch.randn(batch_size_discr_prior, code_size, device=DEVICE)\n",
    "        \n",
    "        opt_discriminator.zero_grad()\n",
    "        \n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "\n",
    "        loss.backward()\n",
    "        opt_discriminator.step()\n",
    "\n",
    "        return loss.item()\n",
    "    \n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73a4cab270cdc85cdf6720275de807dc",
     "grade": false,
     "grade_id": "AAE-label-discriminator",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_step_label_discriminator(inference, discriminator, opt_discriminator):\n",
    "    loss_f = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    def step():\n",
    "        with torch.no_grad():\n",
    "            indx = torch.randint(low=0, high=X_train.shape[0], size=(batch_size, ), device=DEVICE)\n",
    "            X_batch = X_train[indx]\n",
    "            y_real = y_train[indx]\n",
    "            \n",
    "            xi = torch.randn(X_batch.shape[0], xi_size, device=DEVICE)\n",
    "            Z_inferred = inference(X_batch, xi)\n",
    "\n",
    "        opt_discriminator.zero_grad()\n",
    "        \n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        loss.backward()\n",
    "        opt_discriminator.step()\n",
    "\n",
    "        return loss.item()\n",
    "    \n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9788f170e8db9f1060b67f2de4b3154c",
     "grade": false,
     "grade_id": "AAE-AE",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_step_disentanglement_AE(\n",
    "    generator, inference, opt_AE,\n",
    "    discriminator, discriminator_labels,\n",
    "    alpha=1e-1, beta=2e-2\n",
    "):\n",
    "    ce_loss_f = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def step():\n",
    "        with torch.no_grad():\n",
    "            indx = torch.randint(low=0, high=X_train.shape[0], size=(batch_size, ), device=DEVICE)\n",
    "            X_batch = X_train[indx]\n",
    "            y_batch = y_train[indx]\n",
    "            y_onehot_batch = y_one_hot_train[indx]\n",
    "            \n",
    "            xi = torch.randn(X_batch.shape[0], xi_size, device=DEVICE)\n",
    "        \n",
    "        opt_AE.zero_grad()\n",
    "        \n",
    "        ### loss now consists of three term - mse, penalty for distribution of Z,\n",
    "        ### penalty for passing information about the labels.\n",
    "        \n",
    "        # your code here\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        loss.backward()\n",
    "        opt_AE.step()\n",
    "\n",
    "        return mse.item()\n",
    "\n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_step_AAE(step_discriminator, step_AE, discriminator_steps = 4):\n",
    "    def step():\n",
    "        for _ in range(discriminator_steps):\n",
    "            step_discriminator()\n",
    "\n",
    "        return step_AE()\n",
    "    \n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_labels = Discriminator(n, code_size, n_outputs=10).to(DEVICE)\n",
    "discriminator = Discriminator(n, code_size, n_outputs=None).to(DEVICE)\n",
    "\n",
    "generator = Generator(n, code_size + 10).to(DEVICE)\n",
    "inference = Inference(n, code_size, xi_size).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_discriminator_labels = torch.optim.Adam(\n",
    "    lr=2e-3, weight_decay=1e-3,\n",
    "    params=discriminator_labels.parameters()\n",
    ")\n",
    "\n",
    "opt_discriminator = torch.optim.Adam(\n",
    "    lr=2e-3, weight_decay=1e-3,\n",
    "    params=discriminator.parameters()\n",
    ")\n",
    "\n",
    "opt_AE = torch.optim.Adam(\n",
    "    lr=1e-3,\n",
    "    params=list(generator.parameters()) + list(inference.parameters())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### main discriminator step is unchanged...\n",
    "step_discriminator = get_step_discriminator(inference, discriminator, opt_discriminator)\n",
    "\n",
    "step_label_discriminator = get_step_label_discriminator(\n",
    "    inference, discriminator_labels, opt_discriminator_labels\n",
    ")\n",
    "\n",
    "step_AE = get_step_disentanglement_AE(\n",
    "    generator, inference, opt_AE,\n",
    "    discriminator=discriminator,\n",
    "    discriminator_labels=discriminator_labels\n",
    ")\n",
    "\n",
    "def step_discriminators():\n",
    "    step_discriminator()\n",
    "    step_label_discriminator()\n",
    "\n",
    "step_disentanglement = get_step_AAE(step_discriminators, step_AE, discriminator_steps=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_disentanglement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect():\n",
    "    m = 20\n",
    "    tensors = []\n",
    "    with torch.no_grad():\n",
    "        Z = torch.randn(m, code_size, device=DEVICE) \n",
    "\n",
    "        for i in range(10):\n",
    "            labels = torch.tensor(\n",
    "                one_hot(np.repeat(i, m)),\n",
    "                dtype=torch.float32, device=DEVICE\n",
    "            )\n",
    "            Z_labels = torch.cat([Z, labels], dim=1)\n",
    "            X_gen = generator(Z_labels)\n",
    "\n",
    "            tensors.append(X_gen.cpu().numpy().reshape(m, 28, 28))\n",
    "        \n",
    "\n",
    "    plt.figure(figsize=(m * 2, 20))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(\n",
    "        np.concatenate(\n",
    "            np.concatenate(tensors,axis=1),\n",
    "            axis=1\n",
    "        ),\n",
    "        vmin=0, vmax=1,\n",
    "        cmap=plt.cm.Greys\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = iterate(\n",
    "    step_disentanglement,\n",
    "    n_epoches=8, n_steps=n_batches,\n",
    "    callback=lambda : inspect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 20\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_original = X_train[:m]\n",
    "    xi = torch.randn(m, xi_size, device=DEVICE)\n",
    "    Z_inferred = inference(X_original, xi)\n",
    "\n",
    "    tensors = [1 - X_original.cpu().numpy().reshape(m, 28, 28)]\n",
    "    \n",
    "    for i in range(10):\n",
    "        labels = torch.tensor(\n",
    "            one_hot(np.repeat(i, m)),\n",
    "            dtype=torch.float32, device=DEVICE\n",
    "        )\n",
    "        Z_labels = torch.cat([Z_inferred, labels], dim=1)\n",
    "        X_gen = generator(Z_labels)\n",
    "\n",
    "        tensors.append(X_gen.cpu().numpy().reshape(m, 28, 28))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(m * 2, 20))\n",
    "plt.axis('off')\n",
    "plt.imshow(\n",
    "    np.concatenate(\n",
    "        np.concatenate(tensors,axis=1),\n",
    "        axis=1\n",
    "    ),\n",
    "    vmin=0, vmax=1,\n",
    "    cmap=plt.cm.Greys\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
